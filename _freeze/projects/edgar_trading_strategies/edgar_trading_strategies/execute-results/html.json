{
  "hash": "30985765b7f19354d96bb7131fd88c6d",
  "result": {
    "markdown": "---\ntitle: \"EDGAR Trading Strategies\"\ndescription: \"Extracting and parsing data about insider trades on Forms 3, 4, and 5 from the SEC's free public EDGAR API and testing a few trading strategies\"\ntitle-block-banner-color: white\nimage: \"thumbnail.jpg\"\ndraft: false\n---\n\n\n## Intro/Overview\n\nForms 3, 4, and 5 are critical filings with the U.S. Securities and Exchange Commission (SEC) that provide transparency into insider trading activities. They are mandated by Section 16 of the Securities Exchange Act of 1934 and apply to \"insiders\" of a company. For the purpose of these forms, an \"insider\" generally refers to:\n\n- Officers: Executive officers (e.g., CEO, CFO, COO, General Counsel).\n\n- Directors: Members of the company's board of directors.\n\n- Beneficial Owners: Any person or entity who owns more than 10% of any class of a company's equity securities.\n\nThese individuals have access to non-public information about the company, and the purpose of these filings is to prevent unfair use of that information and ensure market fairness. As such, information about the way they trade may provide valuable signals regarding future price movements of the relevant stock, if it is not already priced in by the time an individual trader can access it.\n\n## Setting Up\n\n### Loading Libraries\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(httr)\nlibrary(rvest)\nlibrary(jsonlite)\nlibrary(quantmod)\nlibrary(dplyr)\nlibrary(tidyr)\nlibrary(lubridate)\nlibrary(stringr)\nlibrary(runner)\nlibrary(ggplot2)\nlibrary(purrr)\n```\n:::\n\n\n### Loading S&P500 Price Data\n\nFor this example I will pick a few tickers from the S&P500 to work with. There is no strong reason to focus on these specific companies; membership in the S&P500 is just serving as a proxy for sufficient transaction volume for trading. Focusing on individual tradeable companies is important because getting the Form 3, 4, and 5 data from EDGAR is done at the company level, so the data collection is simplest when identifying specific companies of interest in advance.\n\nThe quantmod package contains a function called getSymbols() which lets the user pick one or more stock symbols and specify a time period, and then it downloads the relevant data from Yahoo Finance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# pick a few tickers and download the data from Yahoo Finance\nsymbols_vec = c(\"SPY\",\"NVDA\",\"MSFT\",\"AMZN\",\"AAPL\",\"META\",\"AVGO\",\"GOOG\",\"GOOGL\",\"TSLA\",\"JPM\",\"WMT\",\"V\",\"LLY\",\"ORCL\",\"NFLX\",\"MA\",\"XOM\",\"COST\",\"PG\",\"JNJ\",\"HD\",\"BAC\")\ngetSymbols(symbols_vec, from = \"2023-01-01\", to = \"2024-12-31\")\n\n# combine adjusted close prices into one dataset\n# a bit weird because quantmod likes to return each ticker\n# as a new object in the environment\ndf_prices = data.frame()\nfor(i in 1:length(symbols_vec)){\n  # keep only the adjusted returns data\n  cmd = paste0(symbols_vec[i], \"=\", symbols_vec[i], \"[,grepl('Adjusted',colnames(\", symbols_vec[i], \"))]\")\n  eval(parse(text = cmd))\n  # combine into one data frame\n  if(i == 1){\n    cmd = paste0(\"df_prices = \", symbols_vec[i])\n    eval(parse(text = cmd))\n  }else{\n    cmd = paste0(\"df_prices = merge(df_prices, \", symbols_vec[i], \")\")\n    eval(parse(text = cmd))\n  }\n}\n\n# Clean up column names\ncolnames(df_prices) = gsub(\".Adjusted\", \"\", colnames(df_prices))\n\n# Add dates to adjusted close prices\ndf_prices = data.frame(date = index(df_prices), df_prices)\n\n# Write to file to avoid pulling every time\nwrite.csv(df_prices, \"df_prices.csv\", row.names = FALSE)\n\n# process price data\nprice_data_processed = df_prices %>%\n  mutate(date = ymd(date)) %>%\n  pivot_longer(-date, names_to = \"ticker\", values_to = \"close_price\") %>%\n  filter(!is.na(close_price) & close_price > 0)\n```\n:::\n\n\n\n\nHere is how the data looks after this initial cleanup.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::kable(head(df_prices))\n```\n\n::: {.cell-output-display}\n|date       |      SPY|     NVDA|     MSFT|  AMZN|     AAPL|     META|     AVGO|     GOOG|    GOOGL|   TSLA|      JPM|      WMT|        V|      LLY|     ORCL|   NFLX|       MA|       XOM|     COST|       PG|      JNJ|       HD|      BAC|\n|:----------|--------:|--------:|--------:|-----:|--------:|--------:|--------:|--------:|--------:|------:|--------:|--------:|--------:|--------:|--------:|------:|--------:|---------:|--------:|--------:|--------:|--------:|--------:|\n|2023-01-03 | 368.1687| 14.30229| 234.8089| 85.82| 123.4706| 124.0594| 53.11102| 89.16996| 88.58871| 108.10| 126.1023| 46.34946| 203.5143| 357.7304| 80.98023| 294.95| 341.6681|  97.81239| 436.2654| 142.4647| 164.8901| 296.2758| 31.30841|\n|2023-01-04 | 371.0110| 14.73590| 224.5377| 85.14| 124.7441| 126.6751| 53.75969| 88.18581| 87.55491| 113.64| 127.2782| 46.40110| 208.6367| 355.8781| 81.71534| 309.41| 349.8946|  98.09706| 439.4222| 143.0851| 166.6853| 299.8584| 31.89703|\n|2023-01-05 | 366.7765| 14.25233| 217.8829| 83.12| 123.4212| 126.2474| 53.25879| 86.25726| 85.68610| 110.34| 127.2500| 46.24295| 207.1648| 351.7812| 81.55091| 309.70| 346.5645| 100.29190| 433.2914| 141.3086| 165.4546| 295.8632| 31.83162|\n|2023-01-06 | 375.1874| 14.84580| 220.4507| 86.08| 127.9624| 129.3106| 56.46476| 87.63905| 86.81931| 113.06| 129.6850| 47.37585| 213.6807| 355.7212| 82.85674| 315.55| 362.8172| 101.50410| 464.7447| 144.6735| 166.7963| 297.7951| 32.14929|\n|2023-01-09 | 374.9748| 15.61412| 222.5971| 87.36| 128.4856| 128.7636| 55.35740| 88.27527| 87.49525| 119.77| 129.1492| 46.78520| 214.5148| 342.8719| 83.90530| 315.17| 366.0736|  99.61231| 460.7793| 142.9064| 162.4749| 298.0577| 31.66345|\n|2023-01-10 | 377.6044| 15.89487| 224.2926| 89.87| 129.0582| 132.2644| 55.16933| 88.71268| 87.89288| 118.85| 130.3056| 46.75615| 216.9582| 345.7339| 83.98299| 327.54| 366.1131| 101.10004| 463.3298| 142.7655| 162.0863| 300.7024| 31.87834|\n:::\n:::\n\n\n## EDGAR Data\n\nAccessing the EDGAR data through the free public API doesn't require any setup. There is no need to register for an API key. As long as you provide a user agent in your request, you can get responses immediately. The tricky part is parsing the responses to get the data you want. The data for Forms 3, 4, 5 are .xml file types, but the content is html which is rendered in the browser. It makes it easy to review any individual form in the browser, but the formatting is not friendly for a script to parse. Here is a screenshot of a Form 4 filing as rendered in the browser as an example of what needs to be parsed:\n\n![https://www.sec.gov/Archives/edgar/data/354950/000035495023000043/xslF345X03/wf-form4_167727677966335.xml](form4_example.jpg){fig-align=\"center\"}\n\n### Data Collection Functions\n\nThe first utility function gets the mapping from the EDGAR database of company ticker to Central Index Key (CIK), which is the unique 10-digit identifier assigned by the SEC to every individual, company, filing agent, or foreign government that files disclosure documents with the SEC. We need the CIK and not the ticker to find the correct information in EDGAR.\n\nThe second function uses the CIK we identified for a given ticker and finds all forms filed for that CIK, then filters the list to just the forms of interest (Forms 3, 4, 5). There are more forms available, but those are not of interest for this project.\n\nThe third function loops through the Form 3, 4, and 5 filings identified by the second function and tries to parse out the relevant information about the insider and the transactions they are reporting. This one is the most problematic because the forms are not identical and the html content is structured to be easy for a human to read in a browser but not for a computer to parse.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nUSER_AGENT = \"Your Name YourEmail@example.com\" # Required by EDGAR API\nBASE_EDGAR_URL = \"https://www.sec.gov/Archives/edgar/data/\"\n\n# Delay between API requests to respect rate limits (adjust as needed)\nREQUEST_DELAY_SEC = 1 # 1 request per second\n\n# Function to get CIK identifier from EDGAR to match with tickers\nget_cik_from_edgar = function() {\n  cat(paste(\"Fetching CIK table from EDGAR\\n\"))\n  search_url = paste0(\"https://www.sec.gov/files/company_tickers.json\")\n  response = GET(search_url, add_headers(`User-Agent` = USER_AGENT))\n  Sys.sleep(REQUEST_DELAY_SEC) # Respect rate limit\n\n  if (http_error(response)) {\n    warning(paste(\"Failed to retrieve ticker data for CIK lookup. Status:\", status_code(response)))\n    return(NULL)\n  }\n\n  content = content(response, \"text\", encoding = \"UTF-8\")\n  ticker_data = fromJSON(content)\n\n  # Bind CIK information to data frame for output\n  cik_entries = do.call('rbind', lapply(ticker_data, function(x){as.data.frame(x)}))\n  cik_entries$cik_str = str_pad(cik_entries$cik_str, width = 10, pad = \"0\")\n  return(cik_entries)\n}\n\n# Function to get recent filings for a CIK (using the company facts API for faster index lookup)\nget_recent_filings = function(cik, form_types = c(\"3\", \"4\", \"5\"), start_date, end_date) {\n  cat(paste(\"Fetching filings for CIK\", cik, \"between\", start_date, \"and\", end_date, \"...\\n\"))\n  company_facts_url = paste0(\"https://data.sec.gov/submissions/CIK\", cik, \".json\")\n  response = GET(company_facts_url, add_headers(`User-Agent` = USER_AGENT))\n  Sys.sleep(REQUEST_DELAY_SEC) # Respect rate limit\n\n  if (http_error(response)) {\n    warning(paste(\"Failed to retrieve company facts for CIK\", cik, \". Status:\", status_code(response)))\n    return(data.frame())\n  }\n\n  content = content(response, \"text\", encoding = \"UTF-8\")\n  company_data = fromJSON(content)\n\n  filings = company_data$filings$recent\n  filings = as.data.frame(filings) # Convert list to data.frame\n  if (is.null(filings) || nrow(filings) == 0) {\n    return(data.frame())\n  }\n\n  # Filter by form type and date\n  filtered_filings = filings %>%\n    filter(form %in% form_types) %>%\n    mutate(filingDate = ymd(filingDate)) %>%\n    filter(filingDate >= start_date & filingDate <= end_date)\n\n  if (nrow(filtered_filings) == 0) {\n    cat(\"No relevant filings found for this CIK in the specified period.\\n\")\n    return(data.frame())\n  }\n\n  # Construct full URL to the XML document for parsing\n  # The primary document is usually the .xml file within the submission folder\n  # Path is typically /Archives/edgar/data/[CIK without leading zeros]/[accessionNumber without dashes]/[fileName]\n  # For Form 3/4/5, fileName is often [ticker]-[date].xml or [CIK]-[date].xml, or just ownership.xml\n  # This part is tricky and might need refinement based on actual filing structures.\n  filtered_filings = filtered_filings %>%\n    mutate(\n      accessionNumber_clean = str_replace_all(accessionNumber, \"-\", \"\"),\n      xml_url = paste0(BASE_EDGAR_URL,\n                       str_remove(cik, \"^0+\"), \"/\",\n                       accessionNumber_clean, \"/\",\n                       primaryDocument)\n    )\n\n  return(filtered_filings)\n}\n\n# Function to parse individual Form 3, 4, or 5 HTML filings (even if .xml extension)\nparse_form_html = function(html_url) {\n  cat(paste(\"Parsing HTML from:\", html_url, \"...\\n\"))\n\n  response = GET(html_url, add_headers(`User-Agent` = USER_AGENT))\n  Sys.sleep(REQUEST_DELAY_SEC) # Respect rate limit\n\n  if (http_error(response)) {\n    warning(paste(\"Failed to retrieve HTML from\", html_url, \". Status:\", status_code(response)))\n    return(NULL)\n  }\n\n  html_content = content(response, \"text\", encoding = \"UTF-8\")\n\n  # Use tryCatch for robust parsing with rvest::read_html\n  parsed_html = tryCatch({\n    read_html(html_content)\n  }, error = function(e) {\n    warning(paste(\"Error parsing HTML from\", html_url, \":\", e$message))\n    return(NULL)\n  })\n\n  if (is.null(parsed_html)) {\n    return(NULL)\n  }\n\n  # --- Extract relevant information using CSS selectors / XPath based on the provided HTML ---\n\n  # Reporting Owner Information\n  # The reporting person's name is in an <a> tag within a table, followed by a <hr>\n  rpt_owner_name <- parsed_html %>%\n    html_element(xpath = \"//table[contains(., 'Name and Address of Reporting Person')]/tr/td/table/tr/td/a\") %>%\n    html_text(trim = TRUE)\n  # The CIK for the reporting person is in the href attribute of the <a> tag\n  rpt_owner_cik <- parsed_html %>%\n    html_element(xpath = \"//table[contains(., 'Name and Address of Reporting Person')]/tr/td/table/tr/td/a\") %>%\n    html_attr(\"href\") %>%\n    str_extract(\"CIK=([0-9]+)\") %>%\n    str_replace(\"CIK=\", \"\")\n\n  # Issuer Information\n  # Issuer name and ticker are in a specific table cell\n  issuer_info_node <- parsed_html %>%\n    html_element(xpath = \"//td[contains(., 'Issuer Name')]/a\")\n  issuer_name <- issuer_info_node %>% html_text(trim = TRUE)\n  issuer_cik <- issuer_info_node %>%\n    html_attr(\"href\") %>%\n    str_extract(\"CIK=([0-9]+)\") %>%\n    str_replace(\"CIK=\", \"\")\n  issuer_ticker <- parsed_html %>%\n    html_element(xpath = \"//td[contains(., 'Issuer Name')]/span[@class='FormData']\") %>%\n    html_text(trim = TRUE)\n\n  # Relationship of Reporting Person(s) to Issuer (Checkboxes)\n  # Look for \"X\" in the sibling <td> of the labels\n  is_director <- parsed_html %>% html_element(xpath = \"//td[text()='Director']/preceding-sibling::td[1]\") %>% html_text(trim = TRUE) == \"X\"\n  is_officer <- parsed_html %>% html_element(xpath = \"//td[text()='Officer (give title below)']/preceding-sibling::td[1]\") %>% html_text(trim = TRUE) == \"X\"\n  is_ten_percent_owner <- parsed_html %>% html_element(xpath = \"//td[text()='10% Owner']/preceding-sibling::td[1]\") %>% html_text(trim = TRUE) == \"X\"\n  is_other <- parsed_html %>% html_element(xpath = \"//td[text()='Other (specify below)']/preceding-sibling::td[1]\") %>% html_text(trim = TRUE) == \"X\"\n\n  # Officer Title (if applicable)\n  rpt_owner_title <- parsed_html %>%\n    html_element(xpath = \"//td[text()='Officer (give title below)']/following-sibling::td[1]\") %>%\n    html_text(trim = TRUE)\n  if (is_officer && rpt_owner_title == \"\") {\n    # Sometimes title is next to \"Officer\" label itself if not a separate cell\n    rpt_owner_title <- parsed_html %>%\n      html_element(xpath = \"//td[text()='Officer (give title below)']/parent::tr/following-sibling::tr/td[@style='color: blue']\") %>% # Check the blue text specifically\n      html_text(trim = TRUE)\n  }\n  # Clean up if no title found or if it's just whitespace\n  if (is.null(rpt_owner_title) || trimws(rpt_owner_title) == \"\") {\n    rpt_owner_title <- NA\n  }\n\n  # --- Non-Derivative Transactions (Table I) ---\n  transactions_list = list()\n\n  # Identify \"Table I\"\n  table_i_node <- parsed_html %>%\n    html_element(xpath = \"//table[.//b[contains(text(), 'Table I - Non-Derivative Securities')]]\")\n\n  if (!is.null(table_i_node)) {\n    # Extract the table content as a data frame.\n    # header = TRUE tells html_table to use the first meaningful rows as headers.\n    # fill = TRUE handles cases with merged cells or inconsistent row lengths by filling with NA.\n    # trim = TRUE removes leading/trailing whitespace from cell values.\n    # convert = FALSE to avoid automatic type conversion, we'll do it manually.\n    non_derivative_data <- tryCatch({\n      html_table(table_i_node, header = TRUE, fill = TRUE, trim = TRUE, convert = FALSE)\n    }, error = function(e) {\n      warning(paste(\"Error extracting Table I:\", e$message))\n      return(NULL)\n    })\n\n    if (!is.null(non_derivative_data) && nrow(non_derivative_data) > 0) {\n      # The table has a complex header with merged cells.\n      # html_table with header=TRUE will likely combine the two header rows.\n      # We need to manually fix column names and select relevant columns.\n\n      # This is where the forms start to differ\n      # depending whether this is Form 3, 4, or 5\n      # this table will have different columns\n      # we will start with Table 4 as it is the most common and has the most columns\n      if (parsed_html %>% html_element(xpath = \"//body\") %>% html_text(trim = TRUE) %>% substr(1,10) == \"SEC Form 4\") {\n        # Rename columns to our desired standard names\n        colnames(non_derivative_data) <- c(\n          \"securityTitle\",\n          \"transactionDate\",\n          \"deemedExecutionDate\", # Keep this for now, though not always used\n          \"transactionCode\",\n          \"vFlag\",\n          \"sharesAcquiredDisposedAmount\",\n          \"acquiredDisposedCode\",\n          \"transactionPricePerShare\",\n          \"postTransactionAmount\",\n          \"directIndirectOwnership\",\n          \"natureOfOwnership\"\n        )\n\n        # Remove header rows that might be duplicated or empty due to `html_table` logic\n        # and remove rows that are entirely NA (often occur due to merged cells or empty rows)\n        non_derivative_data <- non_derivative_data %>%\n          filter(!if_all(everything(), is.na)) %>% # Remove rows with all NAs\n          filter(!grepl(\"Title of Security\", securityTitle, ignore.case = TRUE))\n\n        # Process each row as a transaction or holding\n        if (nrow(non_derivative_data) > 0) {\n          for (i in 1:nrow(non_derivative_data)) {\n            row_data <- non_derivative_data[i, ]\n\n            # Determine if it's a transaction (has a transaction date/code) or a holding\n            is_transaction = !is.na(row_data$transactionDate) && trimws(row_data$transactionDate) != \"\" &&\n                             !is.na(row_data$transactionCode) && trimws(row_data$transactionCode) != \"\"\n\n            temp_df <- data.frame(\n              transactionType = ifelse(is_transaction, \"Transaction\", \"Holding\"),\n              securityTitle = row_data$securityTitle,\n              transactionDate = ifelse(is_transaction, as.character(mdy(row_data$transactionDate)), NA),\n              transactionFormType = NA, # Not explicitly available in this table\n              transactionCode = row_data$transactionCode,\n              equitySwapInvolved = NA, # Not explicitly available in this table\n              sharesAcquiredDisposed = NA,\n              transactionPricePerShare = NA,\n              directIndirectOwnership = row_data$directIndirectOwnership,\n              natureOfOwnership = row_data$natureOfOwnership,\n              postTransactionAmount = NA,\n              stringsAsFactors = FALSE\n            )\n\n            # Populate transaction specific fields only if it's a transaction\n            if (is_transaction) {\n              # Handle shares acquired/disposed. The code (A)/(D) is in `acquiredDisposedCode`\n              # And the amount is in `sharesAcquiredDisposedAmount`\n              shares_val <- as.numeric(gsub(\",|\\\\([^)]*\\\\)\", \"\", row_data$sharesAcquiredDisposedAmount))\n              if (row_data$acquiredDisposedCode == \"D\") {\n                shares_val <- -abs(shares_val) # Represent disposal as negative\n              }\n              temp_df$sharesAcquiredDisposed <- shares_val\n\n              price_val <- as.numeric(gsub(\"[$,]|\\\\([^)]*\\\\)\", \"\", row_data$transactionPricePerShare))\n              temp_df$transactionPricePerShare <- price_val\n            }\n\n            # Post-transaction amount is relevant for both transactions and holdings\n            temp_df$postTransactionAmount <- as.numeric(gsub(\",|\\\\([^)]*\\\\)\", \"\", row_data$postTransactionAmount))\n\n            transactions_list[[length(transactions_list) + 1]] <- temp_df\n          }\n        }\n      } else if (parsed_html %>% html_element(xpath = \"//body\") %>% html_text(trim = TRUE) %>% substr(1,10) == \"SEC Form 3\") {\n        # Form 3 table is a lot like Form 4, which is why the parsing was identical up to here\n        # but it doesn't contain transactions, just beneficial ownership information\n        # so certain columns populated in Form 4 will always be NA here\n        \n        # Rename columns to our desired standard names\n        colnames(non_derivative_data) <- c(\n          \"securityTitle\",\n          \"postTransactionAmount\",\n          \"directIndirectOwnership\",\n          \"natureOfOwnership\"\n        )  \n          \n        # Remove header rows that might be duplicated or empty due to `html_table` logic\n        # and remove rows that are entirely NA (often occur due to merged cells or empty rows)\n        non_derivative_data <- non_derivative_data %>%\n          filter(!if_all(everything(), is.na)) %>% # Remove rows with all NAs\n          filter(!grepl(\"Title of Security\", securityTitle, ignore.case = TRUE))\n        \n        # Process each row as a holding, no transactions in Form 3\n        if (nrow(non_derivative_data) > 0) {\n          for (i in 1:nrow(non_derivative_data)) {\n            row_data <- non_derivative_data[i, ]\n\n            temp_df <- data.frame(\n              transactionType = \"Holding\",\n              securityTitle = row_data$securityTitle,\n              transactionDate = parsed_html %>% html_element(xpath = \"//span[contains(., 'Date of Event Requiring Statement')]/following-sibling::span\") %>% html_text(trim = TRUE) %>% mdy() %>% as.character(), # Can interpret date of reportable event as transaction date for holding\n              transactionFormType = NA, # Not applicable for Form 3\n              transactionCode = NA, # Not applicable for Form 3\n              equitySwapInvolved = NA, # Not applicable for Form 3\n              sharesAcquiredDisposed = NA, # Not applicable for Form 3\n              transactionPricePerShare = NA, # Not applicable for Form 3\n              directIndirectOwnership = row_data$directIndirectOwnership,\n              natureOfOwnership = row_data$natureOfOwnership,\n              postTransactionAmount = as.numeric(gsub(\",|\\\\([^)]*\\\\)\", \"\", row_data$postTransactionAmount)),\n              stringsAsFactors = FALSE\n            )\n\n            transactions_list[[length(transactions_list) + 1]] <- temp_df\n          }\n        }\n      } else if (parsed_html %>% html_element(xpath = \"//body\") %>% html_text(trim = TRUE) %>% substr(1,10) == \"SEC Form 5\") {\n        # Form 5 table is a lot like Form 4, but for some reason parses as having 16 columns\n        # even though it only has 10, so we need to drop the last 6 columns\n        # also, one of the columns from the table in Form 4 is just not present here\n        \n        # Only keep first 10 columns, many duplicate columns are introduced\n        # at the end for some reason\n        non_derivative_data = non_derivative_data[,1:10]  \n        \n        # Rename columns to our desired standard names\n        colnames(non_derivative_data) <- c(\n          \"securityTitle\",\n          \"transactionDate\",\n          \"deemedExecutionDate\",\n          \"transactionCode\",\n          # \"vFlag\", this is the one dropped in Form 5\n          \"sharesAcquiredDisposedAmount\",\n          \"acquiredDisposedCode\",\n          \"transactionPricePerShare\",\n          \"postTransactionAmount\",\n          \"directIndirectOwnership\",\n          \"natureOfOwnership\"\n        )\n          \n        # Remove header rows that might be duplicated or empty due to `html_table` logic\n        # and remove rows that are entirely NA (often occur due to merged cells or empty rows)\n        non_derivative_data <- non_derivative_data %>%\n          filter(!if_all(everything(), is.na)) %>% # Remove rows with all NAs\n          filter(!grepl(\"Title of Security\", securityTitle, ignore.case = TRUE))\n        \n        # Process each row as a transaction or holding\n        if (nrow(non_derivative_data) > 0) {\n          for (i in 1:nrow(non_derivative_data)) {\n            row_data <- non_derivative_data[i, ]\n\n            # Determine if it's a transaction (has a transaction date/code) or a holding\n            is_transaction = !is.na(row_data$transactionDate) && trimws(row_data$transactionDate) != \"\" &&\n                             !is.na(row_data$transactionCode) && trimws(row_data$transactionCode) != \"\"\n\n            temp_df <- data.frame(\n              transactionType = ifelse(is_transaction, \"Transaction\", \"Holding\"),\n              securityTitle = row_data$securityTitle,\n              transactionDate = ifelse(is_transaction, as.character(mdy(row_data$transactionDate)), NA),\n              transactionFormType = NA, # Not explicitly available in this table\n              transactionCode = row_data$transactionCode,\n              equitySwapInvolved = NA, # Not explicitly available in this table\n              sharesAcquiredDisposed = NA,\n              transactionPricePerShare = NA,\n              directIndirectOwnership = row_data$directIndirectOwnership,\n              natureOfOwnership = row_data$natureOfOwnership,\n              postTransactionAmount = NA,\n              stringsAsFactors = FALSE\n            )\n\n            # Populate transaction specific fields only if it's a transaction\n            if (is_transaction) {\n              # Handle shares acquired/disposed. The code (A)/(D) is in `acquiredDisposedCode`\n              # And the amount is in `sharesAcquiredDisposedAmount`\n              shares_val <- as.numeric(gsub(\",|\\\\([^)]*\\\\)\", \"\", row_data$sharesAcquiredDisposedAmount))\n              if (row_data$acquiredDisposedCode == \"D\") {\n                shares_val <- -abs(shares_val) # Represent disposal as negative\n              }\n              temp_df$sharesAcquiredDisposed <- shares_val\n\n              price_val <- as.numeric(gsub(\"[$,]|\\\\([^)]*\\\\)\", \"\", row_data$transactionPricePerShare))\n              temp_df$transactionPricePerShare <- price_val\n            }\n\n            # Post-transaction amount is relevant for both transactions and holdings\n            temp_df$postTransactionAmount <- as.numeric(gsub(\",|\\\\([^)]*\\\\)\", \"\", row_data$postTransactionAmount))\n\n            transactions_list[[length(transactions_list) + 1]] <- temp_df\n          }\n        }\n      } else {\n        warning(paste(\"Body in\", html_url, \"does not start with text SEC Form 3, 4, or 5.\"))\n      }\n    }\n  } else {\n    warning(paste(\"Table I (Non-Derivative Securities) not found in\", html_url))\n  }\n\n\n  # --- Table II - Derivative Securities (Optional) ---\n  # This section would follow a similar logic to Table I if you need to extract derivative transactions.\n  # The XPath and column mapping would need to be adjusted for the derivative table's specific structure.\n\n\n  if (length(transactions_list) == 0) {\n    warning(paste(\"No identifiable non-derivative transaction or holding data found in\", html_url))\n    return(NULL) # No transactions found in this filing\n  }\n\n  transactions_df = bind_rows(transactions_list) %>%\n    # Ensure numeric columns are actually numeric\n    mutate(across(c(sharesAcquiredDisposed, transactionPricePerShare, postTransactionAmount), as.numeric))\n\n  # Add common filing details to each transaction row\n  transactions_df$issuerName = issuer_name\n  transactions_df$issuerCik = issuer_cik\n  transactions_df$issuerTicker = issuer_ticker\n  transactions_df$rptOwnerName = rpt_owner_name\n  transactions_df$rptOwnerCik = rpt_owner_cik\n  transactions_df$rptOfficerTitle = rpt_owner_title\n  transactions_df$isDirector = is_director\n  transactions_df$isOfficer = is_officer\n  transactions_df$isTenPercentOwner = is_ten_percent_owner\n  transactions_df$isOther = is_other\n  transactions_df$filingUrl = html_url\n\n  return(transactions_df)\n}\n```\n:::\n\n\n### Data Collection Main Loop\n\nHere we put together the utility functions above into a loop to collect all the desired data. We start with a list of tickers and a date range. For each ticker, we identify its associated CIK, get the list of related Form 3, 4, and 5 filings within the chosen date range, and then parse each filing into a data frame. At the end we combine all the parsed filing information into one large data frame for analysis.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Get the mapping of tickers to CIK from EDGAR\ncik_table = get_cik_from_edgar()\n\n# Collect EDGAR Form 3, 4, 5 data over the years 2023-2024\ntickers    = symbols_vec[-1]\nstart_date = ymd(\"2023-01-01\")\nend_date   = ymd(\"2024-12-31\")\n\nall_insider_data = list()\nform_types_to_collect = c(\"3\", \"4\", \"5\")\n\nfor (ticker in tickers) {\n  cik = cik_table[cik_table$ticker == ticker,]\n  if (nrow(cik) == 0) {\n    next # Skip if CIK not found\n  }\n  cik = cik$cik_str[1]\n\n  filings = get_recent_filings(cik, form_types_to_collect, start_date, end_date)\n  if (nrow(filings) == 0) {\n    next # Skip if no relevant filings\n  }\n\n  for (i in 1:nrow(filings)) {\n    filing_url = filings$xml_url[i]\n    parsed_data = parse_form_html(filing_url)\n    if (!is.null(parsed_data)) {\n      parsed_data$filingDate = filings$filingDate[i]\n      parsed_data$formType = filings$form[i]\n      all_insider_data[[length(all_insider_data) + 1]] = parsed_data\n    }\n  }\n}\n\nraw_insider_data = bind_rows(all_insider_data)\n\n# Save to disk to avoid re-downloading during development\nsaveRDS(raw_insider_data, \"raw_insider_data.rds\")\n```\n:::\n\n\n\n\n### Spot Check\n\nLet's take a quick look at the data that was collected.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Print count of each type of form\n# each filing can consist of multiple holding\n# and transaction records, so count by unique filing\nraw_insider_data %>%\n  filter(!duplicated(filingUrl)) %>%\n  group_by(formType) %>%\n  summarise(count = n()) %>%\n  knitr::kable()\n```\n\n::: {.cell-output-display}\n|formType | count|\n|:--------|-----:|\n|3        |    55|\n|4        |  3461|\n|5        |    14|\n:::\n\n```{.r .cell-code}\n# Print the first 5 rows for each type of form\nraw_insider_data %>%\n  group_by(formType) %>%\n  slice_head(n = 5) %>%\n  knitr::kable()\n```\n\n::: {.cell-output-display}\n|transactionType |securityTitle                 |transactionDate |transactionFormType |transactionCode |equitySwapInvolved | sharesAcquiredDisposed| transactionPricePerShare|directIndirectOwnership |natureOfOwnership    | postTransactionAmount|issuerName               |issuerCik  |issuerTicker |rptOwnerName        |rptOwnerCik |rptOfficerTitle              |isDirector |isOfficer |isTenPercentOwner |isOther |filingUrl                                                                                             |filingDate |formType |\n|:---------------|:-----------------------------|:---------------|:-------------------|:---------------|:------------------|----------------------:|------------------------:|:-----------------------|:--------------------|---------------------:|:------------------------|:----------|:------------|:-------------------|:-----------|:----------------------------|:----------|:---------|:-----------------|:-------|:-----------------------------------------------------------------------------------------------------|:----------|:--------|\n|Holding         |Common Stock                  |2023-07-31      |NA                  |NA              |NA                 |                     NA|                       NA|D                       |                     |            2614404.00|Serve Robotics Inc. /DE/ |0001832483 |SERV         |NVIDIA CORP         |0001045810  |NA                           |FALSE      |FALSE     |TRUE              |FALSE   |https://www.sec.gov/Archives/edgar/data/1045810/000104581024000231/xslF345X02/wk-form3_1721337425.xml |2024-07-18 |3        |\n|Holding         |Common Stock                  |2023-12-07      |NA                  |NA              |NA                 |                     NA|                       NA|D                       |                     |                429.00|MICROSOFT CORP           |0000789019 |MSFT         |Mason Mark          |0001487290  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/789019/000106299323022250/xslF345X02/form3.xml                |2023-12-08 |3        |\n|Holding         |Common Stock                  |2023-12-07      |NA                  |NA              |NA                 |                     NA|                       NA|D                       |                     |                  0.00|MICROSOFT CORP           |0000789019 |MSFT         |MacGregor Catherine |0001415757  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/789019/000106299323022249/xslF345X02/form3.xml                |2023-12-08 |3        |\n|Holding         |Common Stock                  |2023-11-29      |NA                  |NA              |NA                 |                     NA|                       NA|D                       |                     |              49661.81|MICROSOFT CORP           |0000789019 |MSFT         |Numoto Takeshi      |0001899931  |EVP, Chief Marketing Officer |FALSE      |TRUE      |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/789019/000106299323021742/xslF345X02/form3.xml                |2023-12-01 |3        |\n|Holding         |Class A Common Stock          |2023-10-13      |NA                  |NA              |NA                 |                     NA|                       NA|I                       |See Footnote(1)      |           12677398.00|PLAYSTUDIOS, Inc.        |0001823878 |MYPS         |MICROSOFT CORP      |0000789019  |NA                           |FALSE      |FALSE     |TRUE              |FALSE   |https://www.sec.gov/Archives/edgar/data/789019/000089924323020428/xslF345X02/doc3.xml                 |2023-11-17 |3        |\n|Transaction     |Common Stock                  |2024-12-18      |NA                  |G               |NA                 |                -385000|                   0.0000|I                       |By Trust(4)          |           10275333.00|NVIDIA CORP              |0001045810 |NVDA         |STEVENS MARK A      |0001199039  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1045810/000104581024000337/xslF345X05/wk-form4_1734736726.xml |2024-12-20 |4        |\n|Holding         |Common Stock                  |NA              |NA                  |                |NA                 |                     NA|                       NA|I                       |By the Envy Trust(5) |           16070550.00|NVIDIA CORP              |0001045810 |NVDA         |STEVENS MARK A      |0001199039  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1045810/000104581024000337/xslF345X05/wk-form4_1734736726.xml |2024-12-20 |4        |\n|Holding         |Common Stock                  |NA              |NA                  |                |NA                 |                     NA|                       NA|D                       |                     |           11541602.00|NVIDIA CORP              |0001045810 |NVDA         |STEVENS MARK A      |0001199039  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1045810/000104581024000337/xslF345X05/wk-form4_1734736726.xml |2024-12-20 |4        |\n|Transaction     |Common                        |2024-12-16      |NA                  |S               |NA                 |                 -18591|                 132.6405|I                       |By Trust(2)          |           29652769.00|NVIDIA CORP              |0001045810 |NVDA         |COXE TENCH          |0001197647  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1045810/000122520824010914/xslF345X05/doc4.xml                |2024-12-18 |4        |\n|Transaction     |Common                        |2024-12-16      |NA                  |S               |NA                 |                -244176|                 131.8579|I                       |By Trust(2)          |           29408593.00|NVIDIA CORP              |0001045810 |NVDA         |COXE TENCH          |0001197647  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1045810/000122520824010914/xslF345X05/doc4.xml                |2024-12-18 |4        |\n|Transaction     |Common Stock                  |2024-04-18      |NA                  |W               |NA                 |                     42|                   0.0000|I                       |By spouse(1)         |               6042.00|Apple Inc.               |0000320193 |AAPL         |WAGNER SUSAN        |0001059235  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/320193/000032019324000102/xslF345X05/wk-form5_1727822122.xml  |2024-10-01 |5        |\n|Holding         |Common Stock                  |NA              |NA                  |                |NA                 |                     NA|                       NA|D                       |                     |              60975.00|Apple Inc.               |0000320193 |AAPL         |WAGNER SUSAN        |0001059235  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/320193/000032019324000102/xslF345X05/wk-form5_1727822122.xml  |2024-10-01 |5        |\n|Holding         |Class C Capital Stock         |NA              |NA                  |                |NA                 |                     NA|                       NA|D                       |                     |               3480.00|Alphabet Inc.            |0001652044 |GOOG         |CHAVEZ R. MARTIN    |0001157983  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1652044/000120919124003289/xslF345X05/doc5.xml                |2024-02-13 |5        |\n|Holding         |Class C Google Stock Units(2) |NA              |NA                  |                |NA                 |                     NA|                       NA|D                       |                     |               2486.00|Alphabet Inc.            |0001652044 |GOOG         |CHAVEZ R. MARTIN    |0001157983  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1652044/000120919124003289/xslF345X05/doc5.xml                |2024-02-13 |5        |\n|Holding         |Class C Google Stock Units(3) |NA              |NA                  |                |NA                 |                     NA|                       NA|D                       |                     |               5699.00|Alphabet Inc.            |0001652044 |GOOG         |CHAVEZ R. MARTIN    |0001157983  |NA                           |TRUE       |FALSE     |FALSE             |FALSE   |https://www.sec.gov/Archives/edgar/data/1652044/000120919124003289/xslF345X05/doc5.xml                |2024-02-13 |5        |\n:::\n:::\n\n\nWe can see that the majority of the filings are Form 4 filings, there are only a few Form 3 or 5 filings in this data. If we look at rows 1 and 5 in the Form 3 data we printed out, it is interesting to see that rather than insiders being registered for Nvidia or Microsoft, we are seeing Nvidia and Microsoft acquire a stake of 10% or more in a different company. This is interesting information and might be leveraged for a trading strategy. For example, in recent time periods, companies that Nvidia invests in tend to be favored by market participants when they hear that news. For now, however, we focus on trading the tickers we already specified so these examples will need to be removed from the data.\n\n## Trading Strategies\n\nHere are a few ideas for trading strategies that focus on the chosen tickers and leverage this EDGAR data:\n\n1. __Multiple Bullish Executives:__ If several different executives choose to purchase the stock within a short enough time window, this may be a good indicator that the stock will do well over the near term.\n2. __Buy/Sell Index of Insider Trades:__ Keep a running index of the total dollar value of insider buy/sell transactions. Buy when index is bullish (for example, twice as much buy volume as sell volume) or sell when the reverse occurs.\n3. __Skin in the Game:__ A significant open-market purchase by a newly appointed key executive (like a CEO or CFO) signals strong confidence in the company's future from the person with the newest top-level perspective. This would leverage the Form 3 data.\n\n### Feature Engineering\n\nHere we clean up the EDGAR data a little bit, and then use it to derive the necessary features for each of the three strategies outlines above. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntickers = c(\"NVDA\",\"MSFT\",\"AMZN\",\"AAPL\",\"META\",\"AVGO\",\"GOOG\",\"GOOGL\",\"TSLA\",\"JPM\",\"WMT\",\"V\",\"LLY\",\"ORCL\",\"NFLX\",\"MA\",\"XOM\",\"COST\",\"PG\",\"JNJ\",\"HD\",\"BAC\")\n\n# Preprocess EDGAR Data\nedgar_data_processed = raw_insider_data %>%\n  # remove cases where the company of interest is acquiring a stake in a different company\n  filter(issuerTicker %in% tickers) %>%\n  # Calculate transaction value. Handle cases where price is zero or NA.\n  mutate(transactionValue = ifelse(transactionPricePerShare > 0, abs(sharesAcquiredDisposed * transactionPricePerShare), 0)) %>%\n  # Select relevant columns\n  select(\n    filingDate, formType, issuerCik, issuerTicker, transactionCode, postTransactionAmount,\n    transactionValue, rptOwnerCik, isDirector, isOfficer, isTenPercentOwner\n  ) %>%\n  # For simplicity, we'll use the issuerTicker as our main identifier\n  rename(date = filingDate, ticker = issuerTicker) %>%\n  filter(!is.na(ticker) & ticker != \"\")\n\n# Split data into training (2023) and testing (2024) periods\ntrain_start_date = ymd(\"2023-01-01\")\ntrain_end_date   = ymd(\"2023-12-31\")\ntest_start_date  = ymd(\"2024-01-01\")\ntest_end_date    = ymd(\"2024-12-31\")\n\n\n# STRATEGY 1: Multiple Executive Buying\ngenerate_strategy1_signals <- function(data, exec_threshold = 3, window = 30, holding_period = 90, signal_delay = 1) {\n  signals <- data %>%\n    filter(transactionCode == 'P' & (isOfficer | isDirector)) %>%\n    arrange(ticker, date) %>%\n    group_by(ticker) %>%\n    mutate(unique_buyers = runner(\n      x = rptOwnerCik,\n      k = paste0(window, \" days\"),\n      idx = date,\n      f = function(x) length(unique(x))\n    )) %>%\n    ungroup() %>%\n    filter(unique_buyers >= exec_threshold) %>%\n    group_by(ticker) %>%\n    mutate(days_since_last_signal = date - lag(date, default = first(date) - holding_period - 1)) %>%\n    filter(days_since_last_signal > holding_period) %>%\n    ungroup() %>%\n    # UPDATED: Add signal delay for trade execution\n    transmute(\n      entry_date = date + days(signal_delay),\n      ticker = ticker,\n      signal = \"BUY\",\n      exit_date = entry_date + days(holding_period)\n    )\n  return(signals)\n}\n\n\n# STRATEGY 2: Insider Buy/Sell Index\ngenerate_strategy2_signals <- function(data, lookback_period = 90, buy_threshold = 2.0, holding_period = 90, signal_delay = 1) {\n  daily_volumes <- data %>%\n    filter(transactionCode %in% c('P', 'S') & transactionValue > 0) %>%\n    group_by(ticker, date, transactionCode) %>%\n    summarise(totalValue = sum(transactionValue), .groups = 'drop') %>%\n    tidyr::pivot_wider(names_from = transactionCode, values_from = totalValue, values_fill = 0) %>%\n    rename(buy_volume = P, sell_volume = S)\n\n  index_data <- daily_volumes %>%\n    arrange(ticker, date) %>%\n    group_by(ticker) %>%\n    mutate(\n      rolling_buy = runner(buy_volume, k = paste0(lookback_period, \" days\"), \n                           idx = date, f = sum, na_pad = TRUE),\n      rolling_sell = runner(sell_volume, k = paste0(lookback_period, \" days\"), \n                            idx = date, f = sum, na_pad = TRUE)\n    ) %>%\n    mutate(buy_sell_index = ifelse(rolling_sell > 0, rolling_buy / rolling_sell, rolling_buy)) %>%\n    ungroup() %>%\n    select(date, ticker, buy_sell_index)\n\n  buy_signals <- index_data %>%\n    filter(buy_sell_index > buy_threshold) %>%\n    group_by(ticker) %>%\n    filter(date == min(date)) %>%\n    ungroup() %>%\n    # UPDATED: Add signal delay for trade execution\n    transmute(\n      entry_date = date + days(signal_delay),\n      ticker,\n      signal = \"BUY\",\n      exit_date = entry_date + days(holding_period)\n    )\n  return(buy_signals)\n}\n\n\n# STRATEGY 3: \"Skin in the Game\" (Form 3)\ngenerate_strategy3_signals <- function(data, value_threshold = 10000, holding_period = 180, signal_delay = 1) {\n  signals <- data %>%\n    filter(formType == '3' & (isOfficer | isDirector)) %>%\n    filter(postTransactionAmount >= value_threshold) %>%\n    group_by(ticker) %>%\n    mutate(days_since_last_signal = date - lag(date, default = first(date) - holding_period - 1)) %>%\n    filter(days_since_last_signal > holding_period) %>%\n    ungroup() %>%\n    # UPDATED: Add signal delay for trade execution\n    transmute(\n      entry_date = date + days(signal_delay),\n      ticker = ticker,\n      signal = \"BUY\",\n      exit_date = entry_date + days(holding_period)\n    )\n  return(signals)\n}\n```\n:::\n\n\n### Backtesting Engine\n\nIn order to evaluate these strategies, we need to combine the daily price data for our tickers with the entry and exit signals for each of the strategies. This function will handle the mechanics of entering and exiting positions for each of the strategies and keeping track of the portfolio value over time.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrun_backtest <- function(signals, price_df, portfolio_alloc = 0.1, initial_capital = 100000) {\n  # Ensure signals are sorted by entry date\n  signals <- signals %>% arrange(entry_date)\n  \n  # Get all relevant dates for the simulation\n  trade_dates <- unique(c(signals$entry_date, signals$exit_date))\n  if(length(trade_dates) == 0) return(data.frame(date=as.Date(character()), portfolio_value=numeric()))\n\n  all_dates <- price_df %>% filter(date >= min(trade_dates) & date <= max(trade_dates)) %>% pull(date) %>% unique() %>% sort()\n  if(length(all_dates) == 0) return(data.frame(date=as.Date(character()), portfolio_value=numeric()))\n\n  portfolio <- data.frame(date = all_dates, portfolio_value = initial_capital, cash = initial_capital)\n  active_positions <- data.frame(ticker = character(), purchase_date = as.Date(character()), shares = numeric(), purchase_price = numeric(), exit_date = as.Date(character()))\n\n  for (i in 1:length(all_dates)) {\n    current_date <- all_dates[i]\n    \n    # Carry over cash from previous day if not the first day\n    if (i > 1) {\n      portfolio$cash[i] <- portfolio$cash[i-1]\n    }\n\n    # Exit positions whose exit_date is today or has passed\n    positions_to_exit <- active_positions %>% filter(exit_date <= current_date)\n    if (nrow(positions_to_exit) > 0) {\n      exit_prices <- price_df %>% filter(date == current_date & ticker %in% positions_to_exit$ticker)\n      \n      if(nrow(exit_prices) > 0){\n        cash_inflow <- positions_to_exit %>%\n          left_join(exit_prices, by = \"ticker\") %>%\n          summarise(total_inflow = sum(shares * close_price, na.rm = TRUE)) %>%\n          pull(total_inflow)\n        \n        portfolio$cash[i] <- portfolio$cash[i] + cash_inflow\n        active_positions <- anti_join(active_positions, positions_to_exit, by = c(\"ticker\", \"purchase_date\"))\n      }\n    }\n\n    # Enter new positions scheduled for today\n    trades_today <- signals %>% filter(entry_date == current_date)\n    if (nrow(trades_today) > 0) {\n      entry_prices <- price_df %>% filter(date == current_date & ticker %in% trades_today$ticker)\n      \n      if(nrow(entry_prices) > 0){\n        trades_with_prices <- trades_today %>% left_join(entry_prices, by = \"ticker\")\n        \n        for (j in 1:nrow(trades_with_prices)) {\n          trade <- trades_with_prices[j, ]\n          trade_cost <- initial_capital * portfolio_alloc\n          \n          if (portfolio$cash[i] >= trade_cost && !is.na(trade$close_price)) {\n            portfolio$cash[i] <- portfolio$cash[i] - trade_cost\n            new_position <- data.frame(\n              ticker = trade$ticker,\n              purchase_date = current_date,\n              shares = trade_cost / trade$close_price,\n              purchase_price = trade$close_price,\n              exit_date = trade$exit_date\n            )\n            active_positions <- rbind(active_positions, new_position)\n          }\n        }\n      }\n    }\n    \n    # Update total portfolio value based on current prices of active positions\n    if(nrow(active_positions) > 0){\n      current_prices <- price_df %>% filter(date == current_date & ticker %in% active_positions$ticker)\n      holdings_value <- active_positions %>%\n        left_join(current_prices, by = \"ticker\") %>%\n        # If price is missing for today (e.g., non-trading day), use last known purchase price\n        mutate(current_price = ifelse(is.na(close_price), purchase_price, close_price)) %>%\n        summarise(total_value = sum(shares * current_price)) %>%\n        pull(total_value)\n    } else {\n      holdings_value <- 0\n    }\n    \n    portfolio$portfolio_value[i] <- portfolio$cash[i] + holdings_value\n  }\n  \n  return(portfolio)\n}\n```\n:::\n\n\n### Hyperparameter Tuning\n\nThere are several parameters that we can change for each of the strategies, such as the lookback window, the holding period, etc. We will use the 2023 data as the training data for tuning these parameters to determine the best settings, then evaluate the performance of the strategies under those tuned parameters one the remaining data from 2024.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define data for the training period\ntrain_data <- edgar_data_processed %>% filter(date >= train_start_date & date <= train_end_date)\ntrain_prices <- price_data_processed %>% filter(date >= train_start_date & date <= train_end_date)\n\n# Strategy 1 Tuning\ns1_params <- expand.grid(\n  exec_threshold = c(2, 3),\n  window = c(7, 14, 30),\n  holding_period = c(60, 90),\n  signal_delay = c(1, 2, 7)\n)\n\ns1_results <- s1_params %>% \n  mutate(\n    signals = pmap(list(exec_threshold, window, holding_period, signal_delay), ~generate_strategy1_signals(train_data, ..1, ..2, ..3, ..4)),\n    backtest = map(signals, ~run_backtest(., train_prices)),\n    final_value = map_dbl(backtest, ~if(nrow(.) > 0) tail(.$portfolio_value, 1) else 100000)\n  ) %>%\n  arrange(desc(final_value))\n\nbest_s1_params <- s1_results[1, ]\n# Print top parameters for Strategy 1\nknitr::kable(head(select(s1_results, exec_threshold, window, holding_period, signal_delay, final_value)))\n```\n\n::: {.cell-output-display}\n| exec_threshold| window| holding_period| signal_delay| final_value|\n|--------------:|------:|--------------:|------------:|-----------:|\n|              2|     14|             90|            7|    103809.8|\n|              2|     30|             90|            7|    103809.8|\n|              2|     14|             90|            2|    103799.4|\n|              2|     30|             90|            2|    103799.4|\n|              2|     14|             90|            1|    103783.5|\n|              2|     30|             90|            1|    103783.5|\n:::\n\n```{.r .cell-code}\n# Strategy 2 Tuning\ns2_params <- expand.grid(\n  lookback_period = c(7, 30, 60, 90),\n  buy_threshold = c(2.0, 3.0, 4.0),\n  holding_period = c(60, 90),\n  signal_delay = c(1, 2, 7)\n)\n\ns2_results <- s2_params %>%\n  mutate(\n    signals = pmap(list(lookback_period, buy_threshold, holding_period, signal_delay), ~generate_strategy2_signals(train_data, ..1, ..2, ..3, ..4)),\n    backtest = map(signals, ~run_backtest(., train_prices)),\n    final_value = map_dbl(backtest, ~if(nrow(.) > 0) tail(.$portfolio_value, 1) else 100000)\n  ) %>%\n  arrange(desc(final_value))\n\nbest_s2_params <- s2_results[1, ]\n# Print top parameters for Strategy 2\nknitr::kable(head(select(s2_results, lookback_period, buy_threshold, holding_period, signal_delay, final_value)))\n```\n\n::: {.cell-output-display}\n| lookback_period| buy_threshold| holding_period| signal_delay| final_value|\n|---------------:|-------------:|--------------:|------------:|-----------:|\n|              90|             2|             90|            7|    103389.0|\n|              90|             3|             90|            7|    103389.0|\n|              90|             4|             90|            7|    103389.0|\n|              90|             2|             90|            1|    103005.3|\n|              90|             3|             90|            1|    103005.3|\n|              90|             4|             90|            1|    103005.3|\n:::\n\n```{.r .cell-code}\n# Strategy 3 Tuning\ns3_params <- expand.grid(\n  value_threshold = c(1000, 10000, 100000),\n  holding_period = c(120, 150, 180),\n  signal_delay = c(1, 2, 7)\n)\n\ns3_results <- s3_params %>%\n  mutate(\n    signals = pmap(list(value_threshold, holding_period, signal_delay), ~generate_strategy3_signals(train_data, ..1, ..2, ..3)),\n    backtest = map(signals, ~run_backtest(., train_prices)),\n    final_value = map_dbl(backtest, ~if(nrow(.) > 0) tail(.$portfolio_value, 1) else 100000)\n  ) %>%\n  arrange(desc(final_value))\n\nbest_s3_params <- s3_results[1, ]\n# Print top parameters for Strategy 3\nknitr::kable(head(select(s3_results, value_threshold, holding_period, signal_delay, final_value)))\n```\n\n::: {.cell-output-display}\n| value_threshold| holding_period| signal_delay| final_value|\n|---------------:|--------------:|------------:|-----------:|\n|            1000|            150|            7|    113184.9|\n|            1000|            180|            7|    113030.7|\n|            1000|            180|            1|    111831.8|\n|            1000|            180|            2|    111714.5|\n|            1000|            150|            1|    110623.0|\n|            1000|            150|            2|    110172.4|\n:::\n:::\n\n\nThe signal_delay parameter is incorporated into all of these strategies represents the number of days after the form's filing date that we will trigger the entry flag to enter into the position. This is set to 1 by default since we might not receive data for a form until after the market closes that day. For example, if an insider files Form 4 at end of day January 4, even if we are constantly requesting form data from EDGAR we won't be able to act on it on January 4 because the market will already be closed that day, so the earliest we can enter the position is January 5.\n\nIn this tuning section, we evaluate signal delays of 1, 2, and 7 days as a way to check how robust the strategies are to late entry. Or to say it differently, is the market so sensitive to this information that entering the position as fast as possible is critical to profitability? We can see from the parameter optimization results above that this is not the case. Many of the top parameter combinations have different values for the signal delay parameter, showing that changing the value of this parameter does not result in significant changes in profitability.\n\n### Evaluate Performance\n\nHaving identified the best hyperparameter settings for each strategy, we can now test the trained strategies over the holdout data from 2024 to see how well they perform. For this evaluation, it is useful to also include the S&P500 index as a benchmark. Even if the strategies perform well, in order to provide meaningful values they should be able to outperform a simple strategy of buying and holding an S&P500 ETF such as SPY over the evaluation period.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define data for the testing period\ntest_data <- edgar_data_processed %>% filter(date >= test_start_date & date <= test_end_date)\ntest_prices <- price_data_processed %>% filter(date >= test_start_date & date <= test_end_date)\n\n# Evaluate Strategy 1\ns1_test_signals <- generate_strategy1_signals(test_data, best_s1_params$exec_threshold, best_s1_params$window, best_s1_params$holding_period)\ns1_test_performance <- run_backtest(s1_test_signals, test_prices)\ns1_final_value <- tail(s1_test_performance$portfolio_value, 1)\ncat(sprintf(\"\\nStrategy 1 Final Portfolio Value (2024): $%.2f\\n\", s1_final_value))\n\n# Evaluate Strategy 2\ns2_test_signals <- generate_strategy2_signals(test_data, best_s2_params$lookback_period, best_s2_params$buy_threshold, holding_period = best_s2_params$holding_period)\ns2_test_performance <- run_backtest(s2_test_signals, test_prices)\ns2_final_value <- tail(s2_test_performance$portfolio_value, 1)\ncat(sprintf(\"Strategy 2 Final Portfolio Value (2024): $%.2f\\n\", s2_final_value))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStrategy 2 Final Portfolio Value (2024): $100333.70\n```\n:::\n\n```{.r .cell-code}\n# Evaluate Strategy 3\ns3_test_signals <- generate_strategy3_signals(test_data, best_s3_params$value_threshold, best_s3_params$holding_period)\ns3_test_performance <- run_backtest(s3_test_signals, test_prices)\ns3_final_value <- tail(s3_test_performance$portfolio_value, 1)\ncat(sprintf(\"Strategy 3 Final Portfolio Value (2024): $%.2f\\n\", s3_final_value))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStrategy 3 Final Portfolio Value (2024): $106324.03\n```\n:::\n\n```{.r .cell-code}\n# Evaluate Strategy 4: Benchmark of just buying and holding SPY\ns4_test_signals <- data.frame(entry_date = as.Date(\"2024-01-04\"), ticker = \"SPY\", signal = \"BUY\", exit_date = as.Date(\"2024-12-30\"))\ns4_test_performance <- run_backtest(s4_test_signals, test_prices, portfolio_alloc = 1)\n\n\n# Combine performance data for plotting\n# s1_test_performance$strategy <- \"1_Multiple_Execs\"\ns2_test_performance$strategy <- \"2_Buy_Sell_Index\"\ns3_test_performance$strategy <- \"3_Skin_In_Game\"\ns4_test_performance$strategy <- \"4_SP500_Benchmark\"\n\nall_performance <- rbind(s2_test_performance, s3_test_performance, s4_test_performance)\n\n# Plot the portfolio value over time for 2024\nall_performance %>% ggplot(aes(x = date, y = portfolio_value, color = strategy)) +\n    geom_line() +\n    labs(\n        title = \"Strategy Performance on 2024 Data\",\n        x = \"Date\",\n        y = \"Portfolio Value ($)\",\n        color = \"Strategy\"\n    ) +\n    scale_y_continuous(labels = scales::dollar) +\n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](edgar_trading_strategies_files/figure-html/evaluate-performance-1.png){width=672}\n:::\n:::\n\n\nAfter all that work, it turns out these strategies don't perform very well. Just buying and holding an ETF tracking the S&P500 index provides way better returns. There are a number of factors contributing to this poor performance, but two major causes stand out:\n\n- __Infrequent Signals:__ Strategy 1 didn't trigger any entry flags during the test period, so it doesn't even show up in the final performance evaluation, and even in the training set it only triggered a single entry flag. The other two strategies at least had a few entry flags, but still not that many.\n- __Portfolio Utilization:__ Related to the lack of entry flags, the three strategies used naive portfolio weighting to allocate 10% of the portfolio capital to each new position. However, since there were so few entry flags the portfolio capital was never fully invested in any strategy except in the benchmark strategy. \n\nAt the end of the day, there doesn't seem to be sufficient data to support these strategies, at least as currently designed. Some ideas for future work could include trying to leverage the sale transaction data (there are significantly more sales than purchases in this dataset) and buy put options, or try to leverage the Form 3 data where one company acquires a 10% or higher ownership stake in another as a factor that could drive up the price for the company being acquired.\n\n## Conclusion\n\nThe SEC's EDGAR database contains many regulatory filings, and this analysis showed how to extract information from a few of them and then leverage that information to create trading strategies. While the final evaluation showed that these particular strategies are not very profitable in their current states, it still lays out a useful framework for acquiring data from the free public EDGAR API and thinking about how to evaluate any subsequent trading strategies.\n",
    "supporting": [
      "edgar_trading_strategies_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}